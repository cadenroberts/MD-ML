{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'module.dataset' from '/home/argon/openmm/cgschnet/cgschnet/cgschnet/scripts/tests/../module/dataset.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import sys\n",
    "import random\n",
    "sys.path.append(\"..\")\n",
    "from module import dataset\n",
    "importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make tensors less verbose\n",
    "# torch.Tensor.__repr__ = lambda x : f\"tensor(shape={list(x.shape)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mock_items(n_items, gen_boxes=False, lengths=None):\n",
    "    if not lengths:\n",
    "        lengths = [105,101,66,57,85,67,91,61]\n",
    "    result = []\n",
    "    for k in range(n_items):\n",
    "        coord = [torch.zeros((i, 3),dtype=torch.float) for i in lengths]\n",
    "        embed = [torch.zeros((i),dtype=torch.long) for i in lengths]\n",
    "        force = [i*torch.ones((i, 3),dtype=torch.float) for i in lengths]\n",
    "        if gen_boxes:\n",
    "            boxes = [torch.zeros((1, 3, 3),dtype=torch.long) for i in lengths]\n",
    "        else:\n",
    "            boxes = [torch.tensor([],dtype=torch.long) for i in lengths]\n",
    "        result.append({\"pos\":coord, \"z\":embed, \"force\":force, \"box\":boxes})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = dataset.ProteinBatchCollate(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn(make_mock_items(1))\n",
    "assert len(batched) == 2\n",
    "assert batched[0][\"pos\"].shape == (1, 481, 3)\n",
    "assert batched[0][\"z\"].shape == (1, 481)\n",
    "assert batched[0][\"force\"].shape == (1, 481, 3)\n",
    "assert batched[0][\"box\"].shape == (1, 0)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101, 66, 57, 85, 67]\n",
    "assert batched[1][\"lengths\"] == [91, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn(make_mock_items(2))\n",
    "assert len(batched) == 3\n",
    "assert batched[0][\"pos\"].shape == (2, 206, 3)\n",
    "assert batched[0][\"z\"].shape == (2, 206)\n",
    "assert batched[0][\"force\"].shape == (2, 206, 3)\n",
    "assert batched[0][\"box\"].shape == (2, 0)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101]\n",
    "assert batched[1][\"lengths\"] == [66, 57, 85]\n",
    "assert batched[2][\"lengths\"] == [67, 91, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Molecule 0 is too large (840x8)>500\n"
     ]
    }
   ],
   "source": [
    "assertion_ok = False\n",
    "try:\n",
    "    collate_fn(make_mock_items(8))\n",
    "except AssertionError as e:\n",
    "    assertion_ok = True\n",
    "    print(\"OK:\", str(e))\n",
    "assert assertion_ok, \"Failed to detect too large a batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn(make_mock_items(1, True))\n",
    "assert len(batched) == 2\n",
    "assert batched[0][\"pos\"].shape == (1, 481, 3)\n",
    "assert batched[0][\"z\"].shape == (1, 481)\n",
    "assert batched[0][\"force\"].shape == (1, 481, 3)\n",
    "assert batched[0][\"box\"].shape == (1, len(batched[0][\"lengths\"]), 3, 3)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101, 66, 57, 85, 67]\n",
    "assert batched[1][\"lengths\"] == [91, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn(make_mock_items(2, True))\n",
    "assert len(batched) == 3\n",
    "assert batched[0][\"pos\"].shape == (2, 206, 3)\n",
    "assert batched[0][\"z\"].shape == (2, 206)\n",
    "assert batched[0][\"force\"].shape == (2, 206, 3)\n",
    "assert batched[0][\"box\"].shape == (2, len(batched[0][\"lengths\"]), 3, 3)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101]\n",
    "assert batched[1][\"lengths\"] == [66, 57, 85]\n",
    "assert batched[2][\"lengths\"] == [67, 91, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn_inf = dataset.ProteinBatchCollate(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn_inf(make_mock_items(2, True))\n",
    "assert len(batched) == 1\n",
    "assert batched[0][\"pos\"].shape == (2, 633, 3)\n",
    "assert batched[0][\"z\"].shape == (2, 633)\n",
    "assert batched[0][\"force\"].shape == (2, 633, 3)\n",
    "assert batched[0][\"box\"].shape == (2, len(batched[0][\"lengths\"]), 3, 3)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101, 66, 57, 85, 67, 91, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = collate_fn_inf(make_mock_items(8, True))\n",
    "assert len(batched) == 1\n",
    "assert batched[0][\"pos\"].shape == (8, 633, 3)\n",
    "assert batched[0][\"z\"].shape == (8, 633)\n",
    "assert batched[0][\"force\"].shape == (8, 633, 3)\n",
    "assert batched[0][\"box\"].shape == (8, len(batched[0][\"lengths\"]), 3, 3)\n",
    "assert sum(len(i[\"lengths\"]) for i in batched) == 8\n",
    "assert batched[0][\"lengths\"] == [105, 101, 66, 57, 85, 67, 91, 61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sub batch grouping logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([105, 101, 66, 57, 85, 67, 91, 61],\n",
       " [101, 61, 66, 85, 91, 57, 105, 67],\n",
       " [66, 61, 105, 101, 67, 85, 57, 91],\n",
       " [164, 105, 125, 131, 174],\n",
       " [131, 164, 174, 105, 125],\n",
       " [125, 174, 164, 105, 131])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xTODO: Make shuffle fixed\n",
    "# xTODO: Test Kevin's set of protein sizes\n",
    "# xTODO: Test large and small batch sizes\n",
    "# xTODO: Test at least one more collate_fn size\n",
    "\n",
    "rng = np.random.default_rng(424242)\n",
    "lengths_a0 = [105,101,66,57,85,67,91,61]\n",
    "lengths_a1 = rng.permutation(lengths_a0).tolist()\n",
    "lengths_a2 = rng.permutation(lengths_a0).tolist()\n",
    "lengths_b0 = [164, 105, 125, 131, 174]\n",
    "lengths_b1 = rng.permutation(lengths_b0).tolist()\n",
    "lengths_b2 = rng.permutation(lengths_b0).tolist()\n",
    "lengths_c0 = [500, 50, 25, 500, 25]\n",
    "\n",
    "lengths_a0, lengths_a1, lengths_a2, lengths_b0, lengths_b1, lengths_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(batch):\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    total_batch_size = sum([i[\"force\"].numel() for i in batch])\n",
    "    # print(total_batch_size)\n",
    "    batch_loss = 0\n",
    "    for sub_batch in batch:\n",
    "        sub_batch_size = sub_batch[\"force\"].numel()\n",
    "        # print(sub_batch_size)\n",
    "        loss = criterion(sub_batch[\"force\"], torch.zeros_like(sub_batch[\"force\"])) * (sub_batch_size / total_batch_size)\n",
    "        batch_loss += loss.item() # Standin for the \"backwards\" loss\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4\n",
      "% err = -5.087987586938444e-06\n",
      "% err = -3.3919917246256295e-06\n",
      "% err = -6.783982989026975e-06\n",
      "% err = -5.674174037721364e-06\n",
      "% err = 3.4045047317168564e-06\n",
      "% err = -1.2483181749679069e-05\n",
      "Batch 10\n",
      "% err = 1.2719971556108405e-05\n",
      "% err = 5.087987932106703e-06\n",
      "% err = -1.5263961725310696e-05\n",
      "% err = 7.376426918719855e-06\n",
      "% err = -1.7022522113164093e-06\n",
      "% err = 7.376426918719855e-06\n",
      "Batch 50\n",
      "% err = 6.359984915133379e-06\n",
      "% err = 1.6959959773689011e-06\n",
      "% err = 5.087987932106703e-06\n",
      "% err = 1.0780931650436712e-05\n",
      "% err = 1.0780931650436712e-05\n",
      "% err = 1.0780931650436712e-05\n",
      "Batch Large...\n",
      "  Batch 10\n",
      "% err = 0.0\n",
      "  Batch 20\n",
      "% err = -5.486466916110714e-06\n",
      "  Batch 25\n",
      "% err = 1.218917210366394e-06\n"
     ]
    }
   ],
   "source": [
    "collate_fn_1000 = dataset.ProteinBatchCollate(1000)\n",
    "collate_fn_2000 = dataset.ProteinBatchCollate(2000)\n",
    "collate_fn_10000 = dataset.ProteinBatchCollate(10000)\n",
    "collate_fn_inf = dataset.ProteinBatchCollate(None)\n",
    "\n",
    "print(\"Batch 4\")\n",
    "for lengths in [lengths_a0, lengths_a1, lengths_a2, lengths_b0, lengths_b1, lengths_b2]:\n",
    "    batch = make_mock_items(4, False, lengths=lengths)\n",
    "    inf_loss = test_batch(collate_fn_inf(batch))\n",
    "    batched_loss = test_batch(collate_fn_1000(batch))\n",
    "    print(\"% err =\", 100*(batched_loss - inf_loss)/inf_loss)\n",
    "\n",
    "print(\"Batch 10\")\n",
    "for lengths in [lengths_a0, lengths_a1, lengths_a2, lengths_b0, lengths_b1, lengths_b2]:\n",
    "    batch = make_mock_items(10, False, lengths=lengths)\n",
    "    inf_loss = test_batch(collate_fn_inf(batch))\n",
    "    batched_loss = test_batch(collate_fn_2000(batch))\n",
    "    print(\"% err =\", 100*(batched_loss - inf_loss)/inf_loss)\n",
    "\n",
    "print(\"Batch 50\")\n",
    "for lengths in [lengths_a0, lengths_a1, lengths_a2, lengths_b0, lengths_b1, lengths_b2]:\n",
    "    batch = make_mock_items(50, False, lengths=lengths)\n",
    "    inf_loss = test_batch(collate_fn_inf(batch))\n",
    "    batched_loss = test_batch(collate_fn_10000(batch))\n",
    "    print(\"% err =\", 100*(batched_loss - inf_loss)/inf_loss)\n",
    "\n",
    "print(\"Batch Large...\")\n",
    "for i in [10,20,25]:\n",
    "    for lengths in [lengths_c0]:\n",
    "        print(\"  Batch\",i)\n",
    "        batch = make_mock_items(i, False, lengths=lengths)\n",
    "        # print([i[\"lengths\"] for i in collate_fn_10000(batch)])\n",
    "        inf_loss = test_batch(collate_fn_inf(batch))\n",
    "        batched_loss = test_batch(collate_fn_10000(batch))\n",
    "        print(\"% err =\", 100*(batched_loss - inf_loss)/inf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
